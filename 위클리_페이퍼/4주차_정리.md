# **8.25~8.29(4주차) 위클리 페이퍼**

## 질문
- 결정 트리의 장점과 단점은 무엇인가요?
- 부스팅은 어떤 특징을 가진 앙상블 기법인가요? 토픽에서 배운 AdaBoost 이외의 부스팅 모델에는 무엇이 있는지에 대해 구글 등을 활용하여 직접 리서치해보고, 각 부스팅 모델의 특징, 장단점에 대해 말해주세요.
- 차원 축소 기법인 주성분 분석과 요인 분석의 차이는 무엇인지 설명해 주세요.

---
## 1. 결정 트리의 장점과 단점은 무엇인가요?

### 결정트리란?

- 데이터를 조건에 따라 분할하며 분류/회귀를 수행하는 트리 기반 모델.
- 한 번의 분기때마다 변수 영역을 두 개로 구분함.
- 질문이나 정답이 담긴 네모 상자를 **노드**라고 함.
- 가장 첫 질문 : **루트 노드**
- 정답이 담긴 마지막 노드 : **터미널 노드(terminal node)** 또는 **리프 노드(leaf node)**

### 장점 및 단점
| 구분     | 항목               | 설명                                      |
| ------ | ---------------- | --------------------------------------- |
| **장점** | 직관적              | 트리 형태로 분기 → 사람이 보기 쉽고 이해 가능             |
|        | 스케일링 불필요         | StandardScaler, MinMaxScaler 없이 사용 가능   |
|        | 범주형 처리 가능        | 인코딩 없이 범주형 변수 처리 가능 (일부 구현체)            |
|        | 비선형 관계 처리 가능     | 분기 구조이기 때문에 비선형 경계도 학습 가능               |
|        | 빠른 학습 속도         | 단일 모델 학습 속도가 빠름                         |
|        | 시각화 가능           | `plot_tree()` 등으로 구조 확인 가능              |
| **단점** | 과적합(overfitting) | 트리 깊이를 제한하지 않으면 학습 성능은 높지만 test 성능은 떨어짐 |
|        | 작은 변화에 민감        | 데이터가 조금만 바뀌어도 트리 구조가 크게 달라짐             |
|        | 불안정성             | 결정 기준이 다양해서 동일 데이터라도 구조가 달라질 수 있음       |
|        | 예측 성능 제한적        | 단일 결정 트리는 앙상블보다 성능이 낮음                  |


---

## 2. 부스팅은 어떤 특징을 가진 앙상블 기법인가요?
+ 앙상블 알고리즘의 주요 유형 (보팅, 배깅, 부스팅, 스태킹)
  
### 부스팅이란?
- 머신러닝 앙상블 기법 중 하나로, 약한 학습기를 순차적으로 결합하여 예측/분류 성능을 높이는 알고리즘 
- 예측 데이터 분석의 오차를 줄이기 위해 기계 학습에 사용되는 방법(편향 감소)

### 부스팅 모델 종류
| 모델                                  | 특징                                              | 장점                            | 단점                                 |
| ----------------------------------- | ----------------------------------------------- | ----------------------------- | ---------------------------------- |
| **AdaBoost**                        | 약한 분류기(주로 결정 stump)를 순차적으로 학습하며 오분류 데이터에 가중치 부여 | 구현 간단, 직관적, 과적합 억제 효과         | 이상치(outlier)에 민감, 복잡한 데이터셋에선 성능 한계 |
| **GBM (Gradient Boosting Machine)** | 경사하강법으로 잔여 오차를 줄이며 순차적으로 트리 학습                  | 다양한 손실 함수 적용 가능, 높은 예측 성능     | 학습 속도 느림, 과적합 위험 높음                |
| **XGBoost**                         | GBM 개선 버전, 정규화와 분산처리를 통해 속도·성능 강화               | 빠른 학습, 과적합 방지(정규화), 병렬 처리 지원  | 파라미터가 많아 튜닝 복잡                     |
| **LightGBM**                        | 히스토그램 기반 학습, 리프 중심(Tree Leaf-wise) 성장 방식        | 매우 빠른 학습, 메모리 효율적, 대용량 데이터 적합 | 작은 데이터셋에서는 과적합 발생 가능               |
| **CatBoost**                        | 범주형 변수 처리에 특화, 순차 부스팅(Ordered Boosting) 적용      | 범주형 변수 자동 처리, 튜닝 용이, 과적합 억제   | 학습 속도가 다소 느릴 수 있음, 모델 크기가 큼        |

---

## 3. 차원 축소 기법인 주성분 분석과 요인 분석의 차이는 무엇인가요?

### 1) 주성분 분석(PCA)

- 차원 축소에 쓰이는 기법으로, 머신러닝, 데이터마이닝, 통계분석, 노이즈 제거 등 다양한 분야에 사용됨
- 여러 변수 간 상관관계를 이용해서 이 변수들의 분산을 가장 잘 설명하는 새로운 변수, 즉 '주성분'을 찾는 기법
- **목적** : 데이터의 차원 축소 및 정보 요약 (데이터의 복잡성 줄임)
- 핵심 아이디어 : 변동(분산)이 가장 큰 방향을 새로운 축으로 삼아 데이터 투영
- 주요 용도 : 데이터 시각화, 노이즈 제거, 기계학습 모델의 특성 추출 등

### 2) 요인 분석(FA) 
- 관찰된 변수들 간의 상관관계를 바탕으로, 변수들에 공통적으로 영향을 미치는 잠재적인 구조, 즉 '요인'을 찾아내는 기법
- **목적** : 데이터의 잠재적 구조 파악 및 변수들의 그룹화
- 핵심 아이디어 : 관찰된 변수들은 측정 불가능한 잠재 요인과 각 변수 고유의 오차로 구성된다고 가정
- 주요 용도 : 소비자 행동 분석, 성격 특성 파악, 설문조사의 타당성 검증 등

| 구분 | 주성분 분석 (PCA) | 요인분석 (FA) |
| :--- | :--- | :--- |
| **목적** | **정보의 요약**, 차원 축소 | **잠재 구조의 발견**, 원인 규명 |
| **관점** | "데이터를 어떻게 하면 잘 대표할 수 있을까?" | "이 데이터는 왜 이런 모습을 보일까?" |
| **방향성** | 관찰 변수들 ➡ 주성분 | 잠재 요인 ➡ 관찰 변수들 |
| **주요 질문**| 변수들의 분산을 가장 잘 설명하는 축은 무엇인가? | 변수들 간의 상관관계를 유발하는 공통 요인은 무엇인가? |
| **분석 대상**| **전체 분산** (고유 분산 + 공통 분산) | **공통 분산** (변수들이 공유하는 분산) |
| **결과** | 서로 상관관계가 없는 '주성분' | 변수들을 설명하는 '잠재 요인' |
